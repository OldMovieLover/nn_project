{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53e747d9-2e05-4e3d-a656-aa11ea78efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchutils as tu\n",
    "import torch.nn as nn\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "from torchvision.models import resnet50, DenseNet121_Weights\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca753f6f-608d-42d1-a949-8c96feafd26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dbbfff9-4209-4711-aa68-0f9908a5c369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc871826-211b-4f11-9875-060bbf796efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = \"\"\"\n",
    "1 001.Black_footed_Albatross\n",
    "2 002.Laysan_Albatross\n",
    "3 003.Sooty_Albatross\n",
    "4 004.Groove_billed_Ani\n",
    "5 005.Crested_Auklet\n",
    "6 006.Least_Auklet\n",
    "7 007.Parakeet_Auklet\n",
    "8 008.Rhinoceros_Auklet\n",
    "9 009.Brewer_Blackbird\n",
    "10 010.Red_winged_Blackbird\n",
    "11 011.Rusty_Blackbird\n",
    "12 012.Yellow_headed_Blackbird\n",
    "13 013.Bobolink\n",
    "14 014.Indigo_Bunting\n",
    "15 015.Lazuli_Bunting\n",
    "16 016.Painted_Bunting\n",
    "17 017.Cardinal\n",
    "18 018.Spotted_Catbird\n",
    "19 019.Gray_Catbird\n",
    "20 020.Yellow_breasted_Chat\n",
    "21 021.Eastern_Towhee\n",
    "22 022.Chuck_will_Widow\n",
    "23 023.Brandt_Cormorant\n",
    "24 024.Red_faced_Cormorant\n",
    "25 025.Pelagic_Cormorant\n",
    "26 026.Bronzed_Cowbird\n",
    "27 027.Shiny_Cowbird\n",
    "28 028.Brown_Creeper\n",
    "29 029.American_Crow\n",
    "30 030.Fish_Crow\n",
    "31 031.Black_billed_Cuckoo\n",
    "32 032.Mangrove_Cuckoo\n",
    "33 033.Yellow_billed_Cuckoo\n",
    "34 034.Gray_crowned_Rosy_Finch\n",
    "35 035.Purple_Finch\n",
    "36 036.Northern_Flicker\n",
    "37 037.Acadian_Flycatcher\n",
    "38 038.Great_Crested_Flycatcher\n",
    "39 039.Least_Flycatcher\n",
    "40 040.Olive_sided_Flycatcher\n",
    "41 041.Scissor_tailed_Flycatcher\n",
    "42 042.Vermilion_Flycatcher\n",
    "43 043.Yellow_bellied_Flycatcher\n",
    "44 044.Frigatebird\n",
    "45 045.Northern_Fulmar\n",
    "46 046.Gadwall\n",
    "47 047.American_Goldfinch\n",
    "48 048.European_Goldfinch\n",
    "49 049.Boat_tailed_Grackle\n",
    "50 050.Eared_Grebe\n",
    "51 051.Horned_Grebe\n",
    "52 052.Pied_billed_Grebe\n",
    "53 053.Western_Grebe\n",
    "54 054.Blue_Grosbeak\n",
    "55 055.Evening_Grosbeak\n",
    "56 056.Pine_Grosbeak\n",
    "57 057.Rose_breasted_Grosbeak\n",
    "58 058.Pigeon_Guillemot\n",
    "59 059.California_Gull\n",
    "60 060.Glaucous_winged_Gull\n",
    "61 061.Heermann_Gull\n",
    "62 062.Herring_Gull\n",
    "63 063.Ivory_Gull\n",
    "64 064.Ring_billed_Gull\n",
    "65 065.Slaty_backed_Gull\n",
    "66 066.Western_Gull\n",
    "67 067.Anna_Hummingbird\n",
    "68 068.Ruby_throated_Hummingbird\n",
    "69 069.Rufous_Hummingbird\n",
    "70 070.Green_Violetear\n",
    "71 071.Long_tailed_Jaeger\n",
    "72 072.Pomarine_Jaeger\n",
    "73 073.Blue_Jay\n",
    "74 074.Florida_Jay\n",
    "75 075.Green_Jay\n",
    "76 076.Dark_eyed_Junco\n",
    "77 077.Tropical_Kingbird\n",
    "78 078.Gray_Kingbird\n",
    "79 079.Belted_Kingfisher\n",
    "80 080.Green_Kingfisher\n",
    "81 081.Pied_Kingfisher\n",
    "82 082.Ringed_Kingfisher\n",
    "83 083.White_breasted_Kingfisher\n",
    "84 084.Red_legged_Kittiwake\n",
    "85 085.Horned_Lark\n",
    "86 086.Pacific_Loon\n",
    "87 087.Mallard\n",
    "88 088.Western_Meadowlark\n",
    "89 089.Hooded_Merganser\n",
    "90 090.Red_breasted_Merganser\n",
    "91 091.Mockingbird\n",
    "92 092.Nighthawk\n",
    "93 093.Clark_Nutcracker\n",
    "94 094.White_breasted_Nuthatch\n",
    "95 095.Baltimore_Oriole\n",
    "96 096.Hooded_Oriole\n",
    "97 097.Orchard_Oriole\n",
    "98 098.Scott_Oriole\n",
    "99 099.Ovenbird\n",
    "100 100.Brown_Pelican\n",
    "101 101.White_Pelican\n",
    "102 102.Western_Wood_Pewee\n",
    "103 103.Sayornis\n",
    "104 104.American_Pipit\n",
    "105 105.Whip_poor_Will\n",
    "106 106.Horned_Puffin\n",
    "107 107.Common_Raven\n",
    "108 108.White_necked_Raven\n",
    "109 109.American_Redstart\n",
    "110 110.Geococcyx\n",
    "111 111.Loggerhead_Shrike\n",
    "112 112.Great_Grey_Shrike\n",
    "113 113.Baird_Sparrow\n",
    "114 114.Black_throated_Sparrow\n",
    "115 115.Brewer_Sparrow\n",
    "116 116.Chipping_Sparrow\n",
    "117 117.Clay_colored_Sparrow\n",
    "118 118.House_Sparrow\n",
    "119 119.Field_Sparrow\n",
    "120 120.Fox_Sparrow\n",
    "121 121.Grasshopper_Sparrow\n",
    "122 122.Harris_Sparrow\n",
    "123 123.Henslow_Sparrow\n",
    "124 124.Le_Conte_Sparrow\n",
    "125 125.Lincoln_Sparrow\n",
    "126 126.Nelson_Sharp_tailed_Sparrow\n",
    "127 127.Savannah_Sparrow\n",
    "128 128.Seaside_Sparrow\n",
    "129 129.Song_Sparrow\n",
    "130 130.Tree_Sparrow\n",
    "131 131.Vesper_Sparrow\n",
    "132 132.White_crowned_Sparrow\n",
    "133 133.White_throated_Sparrow\n",
    "134 134.Cape_Glossy_Starling\n",
    "135 135.Bank_Swallow\n",
    "136 136.Barn_Swallow\n",
    "137 137.Cliff_Swallow\n",
    "138 138.Tree_Swallow\n",
    "139 139.Scarlet_Tanager\n",
    "140 140.Summer_Tanager\n",
    "141 141.Artic_Tern\n",
    "142 142.Black_Tern\n",
    "143 143.Caspian_Tern\n",
    "144 144.Common_Tern\n",
    "145 145.Elegant_Tern\n",
    "146 146.Forsters_Tern\n",
    "147 147.Least_Tern\n",
    "148 148.Green_tailed_Towhee\n",
    "149 149.Brown_Thrasher\n",
    "150 150.Sage_Thrasher\n",
    "151 151.Black_capped_Vireo\n",
    "152 152.Blue_headed_Vireo\n",
    "153 153.Philadelphia_Vireo\n",
    "154 154.Red_eyed_Vireo\n",
    "155 155.Warbling_Vireo\n",
    "156 156.White_eyed_Vireo\n",
    "157 157.Yellow_throated_Vireo\n",
    "158 158.Bay_breasted_Warbler\n",
    "159 159.Black_and_white_Warbler\n",
    "160 160.Black_throated_Blue_Warbler\n",
    "161 161.Blue_winged_Warbler\n",
    "162 162.Canada_Warbler\n",
    "163 163.Cape_May_Warbler\n",
    "164 164.Cerulean_Warbler\n",
    "165 165.Chestnut_sided_Warbler\n",
    "166 166.Golden_winged_Warbler\n",
    "167 167.Hooded_Warbler\n",
    "168 168.Kentucky_Warbler\n",
    "169 169.Magnolia_Warbler\n",
    "170 170.Mourning_Warbler\n",
    "171 171.Myrtle_Warbler\n",
    "172 172.Nashville_Warbler\n",
    "173 173.Orange_crowned_Warbler\n",
    "174 174.Palm_Warbler\n",
    "175 175.Pine_Warbler\n",
    "176 176.Prairie_Warbler\n",
    "177 177.Prothonotary_Warbler\n",
    "178 178.Swainson_Warbler\n",
    "179 179.Tennessee_Warbler\n",
    "180 180.Wilson_Warbler\n",
    "181 181.Worm_eating_Warbler\n",
    "182 182.Yellow_Warbler\n",
    "183 183.Northern_Waterthrush\n",
    "184 184.Louisiana_Waterthrush\n",
    "185 185.Bohemian_Waxwing\n",
    "186 186.Cedar_Waxwing\n",
    "187 187.American_Three_toed_Woodpecker\n",
    "188 188.Pileated_Woodpecker\n",
    "189 189.Red_bellied_Woodpecker\n",
    "190 190.Red_cockaded_Woodpecker\n",
    "191 191.Red_headed_Woodpecker\n",
    "192 192.Downy_Woodpecker\n",
    "193 193.Bewick_Wren\n",
    "194 194.Cactus_Wren\n",
    "195 195.Carolina_Wren\n",
    "196 196.House_Wren\n",
    "197 197.Marsh_Wren\n",
    "198 198.Rock_Wren\n",
    "199 199.Winter_Wren\n",
    "200 200.Common_Yellowthroat\n",
    "\"\"\"\n",
    "\n",
    "# Разбиваем строки по переводу строки\n",
    "lines = data.strip().split('\\n')\n",
    "\n",
    "# Извлекаем названия птиц, удаляя префиксы с номерами\n",
    "bird_names = [line.split(' ', 1)[1].split('.', 1)[1] for line in lines]\n",
    "\n",
    "\n",
    "\n",
    "# Выводим результат\n",
    "#for name in bird_names:\n",
    "#    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9af405c-495f-47ee-958d-06641a6c09bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Black_footed_Albatross',\n",
       " 'Laysan_Albatross',\n",
       " 'Sooty_Albatross',\n",
       " 'Groove_billed_Ani',\n",
       " 'Crested_Auklet',\n",
       " 'Least_Auklet',\n",
       " 'Parakeet_Auklet',\n",
       " 'Rhinoceros_Auklet',\n",
       " 'Brewer_Blackbird',\n",
       " 'Red_winged_Blackbird',\n",
       " 'Rusty_Blackbird',\n",
       " 'Yellow_headed_Blackbird',\n",
       " 'Bobolink',\n",
       " 'Indigo_Bunting',\n",
       " 'Lazuli_Bunting',\n",
       " 'Painted_Bunting',\n",
       " 'Cardinal',\n",
       " 'Spotted_Catbird',\n",
       " 'Gray_Catbird',\n",
       " 'Yellow_breasted_Chat',\n",
       " 'Eastern_Towhee',\n",
       " 'Chuck_will_Widow',\n",
       " 'Brandt_Cormorant',\n",
       " 'Red_faced_Cormorant',\n",
       " 'Pelagic_Cormorant',\n",
       " 'Bronzed_Cowbird',\n",
       " 'Shiny_Cowbird',\n",
       " 'Brown_Creeper',\n",
       " 'American_Crow',\n",
       " 'Fish_Crow',\n",
       " 'Black_billed_Cuckoo',\n",
       " 'Mangrove_Cuckoo',\n",
       " 'Yellow_billed_Cuckoo',\n",
       " 'Gray_crowned_Rosy_Finch',\n",
       " 'Purple_Finch',\n",
       " 'Northern_Flicker',\n",
       " 'Acadian_Flycatcher',\n",
       " 'Great_Crested_Flycatcher',\n",
       " 'Least_Flycatcher',\n",
       " 'Olive_sided_Flycatcher',\n",
       " 'Scissor_tailed_Flycatcher',\n",
       " 'Vermilion_Flycatcher',\n",
       " 'Yellow_bellied_Flycatcher',\n",
       " 'Frigatebird',\n",
       " 'Northern_Fulmar',\n",
       " 'Gadwall',\n",
       " 'American_Goldfinch',\n",
       " 'European_Goldfinch',\n",
       " 'Boat_tailed_Grackle',\n",
       " 'Eared_Grebe',\n",
       " 'Horned_Grebe',\n",
       " 'Pied_billed_Grebe',\n",
       " 'Western_Grebe',\n",
       " 'Blue_Grosbeak',\n",
       " 'Evening_Grosbeak',\n",
       " 'Pine_Grosbeak',\n",
       " 'Rose_breasted_Grosbeak',\n",
       " 'Pigeon_Guillemot',\n",
       " 'California_Gull',\n",
       " 'Glaucous_winged_Gull',\n",
       " 'Heermann_Gull',\n",
       " 'Herring_Gull',\n",
       " 'Ivory_Gull',\n",
       " 'Ring_billed_Gull',\n",
       " 'Slaty_backed_Gull',\n",
       " 'Western_Gull',\n",
       " 'Anna_Hummingbird',\n",
       " 'Ruby_throated_Hummingbird',\n",
       " 'Rufous_Hummingbird',\n",
       " 'Green_Violetear',\n",
       " 'Long_tailed_Jaeger',\n",
       " 'Pomarine_Jaeger',\n",
       " 'Blue_Jay',\n",
       " 'Florida_Jay',\n",
       " 'Green_Jay',\n",
       " 'Dark_eyed_Junco',\n",
       " 'Tropical_Kingbird',\n",
       " 'Gray_Kingbird',\n",
       " 'Belted_Kingfisher',\n",
       " 'Green_Kingfisher',\n",
       " 'Pied_Kingfisher',\n",
       " 'Ringed_Kingfisher',\n",
       " 'White_breasted_Kingfisher',\n",
       " 'Red_legged_Kittiwake',\n",
       " 'Horned_Lark',\n",
       " 'Pacific_Loon',\n",
       " 'Mallard',\n",
       " 'Western_Meadowlark',\n",
       " 'Hooded_Merganser',\n",
       " 'Red_breasted_Merganser',\n",
       " 'Mockingbird',\n",
       " 'Nighthawk',\n",
       " 'Clark_Nutcracker',\n",
       " 'White_breasted_Nuthatch',\n",
       " 'Baltimore_Oriole',\n",
       " 'Hooded_Oriole',\n",
       " 'Orchard_Oriole',\n",
       " 'Scott_Oriole',\n",
       " 'Ovenbird',\n",
       " 'Brown_Pelican',\n",
       " 'White_Pelican',\n",
       " 'Western_Wood_Pewee',\n",
       " 'Sayornis',\n",
       " 'American_Pipit',\n",
       " 'Whip_poor_Will',\n",
       " 'Horned_Puffin',\n",
       " 'Common_Raven',\n",
       " 'White_necked_Raven',\n",
       " 'American_Redstart',\n",
       " 'Geococcyx',\n",
       " 'Loggerhead_Shrike',\n",
       " 'Great_Grey_Shrike',\n",
       " 'Baird_Sparrow',\n",
       " 'Black_throated_Sparrow',\n",
       " 'Brewer_Sparrow',\n",
       " 'Chipping_Sparrow',\n",
       " 'Clay_colored_Sparrow',\n",
       " 'House_Sparrow',\n",
       " 'Field_Sparrow',\n",
       " 'Fox_Sparrow',\n",
       " 'Grasshopper_Sparrow',\n",
       " 'Harris_Sparrow',\n",
       " 'Henslow_Sparrow',\n",
       " 'Le_Conte_Sparrow',\n",
       " 'Lincoln_Sparrow',\n",
       " 'Nelson_Sharp_tailed_Sparrow',\n",
       " 'Savannah_Sparrow',\n",
       " 'Seaside_Sparrow',\n",
       " 'Song_Sparrow',\n",
       " 'Tree_Sparrow',\n",
       " 'Vesper_Sparrow',\n",
       " 'White_crowned_Sparrow',\n",
       " 'White_throated_Sparrow',\n",
       " 'Cape_Glossy_Starling',\n",
       " 'Bank_Swallow',\n",
       " 'Barn_Swallow',\n",
       " 'Cliff_Swallow',\n",
       " 'Tree_Swallow',\n",
       " 'Scarlet_Tanager',\n",
       " 'Summer_Tanager',\n",
       " 'Artic_Tern',\n",
       " 'Black_Tern',\n",
       " 'Caspian_Tern',\n",
       " 'Common_Tern',\n",
       " 'Elegant_Tern',\n",
       " 'Forsters_Tern',\n",
       " 'Least_Tern',\n",
       " 'Green_tailed_Towhee',\n",
       " 'Brown_Thrasher',\n",
       " 'Sage_Thrasher',\n",
       " 'Black_capped_Vireo',\n",
       " 'Blue_headed_Vireo',\n",
       " 'Philadelphia_Vireo',\n",
       " 'Red_eyed_Vireo',\n",
       " 'Warbling_Vireo',\n",
       " 'White_eyed_Vireo',\n",
       " 'Yellow_throated_Vireo',\n",
       " 'Bay_breasted_Warbler',\n",
       " 'Black_and_white_Warbler',\n",
       " 'Black_throated_Blue_Warbler',\n",
       " 'Blue_winged_Warbler',\n",
       " 'Canada_Warbler',\n",
       " 'Cape_May_Warbler',\n",
       " 'Cerulean_Warbler',\n",
       " 'Chestnut_sided_Warbler',\n",
       " 'Golden_winged_Warbler',\n",
       " 'Hooded_Warbler',\n",
       " 'Kentucky_Warbler',\n",
       " 'Magnolia_Warbler',\n",
       " 'Mourning_Warbler',\n",
       " 'Myrtle_Warbler',\n",
       " 'Nashville_Warbler',\n",
       " 'Orange_crowned_Warbler',\n",
       " 'Palm_Warbler',\n",
       " 'Pine_Warbler',\n",
       " 'Prairie_Warbler',\n",
       " 'Prothonotary_Warbler',\n",
       " 'Swainson_Warbler',\n",
       " 'Tennessee_Warbler',\n",
       " 'Wilson_Warbler',\n",
       " 'Worm_eating_Warbler',\n",
       " 'Yellow_Warbler',\n",
       " 'Northern_Waterthrush',\n",
       " 'Louisiana_Waterthrush',\n",
       " 'Bohemian_Waxwing',\n",
       " 'Cedar_Waxwing',\n",
       " 'American_Three_toed_Woodpecker',\n",
       " 'Pileated_Woodpecker',\n",
       " 'Red_bellied_Woodpecker',\n",
       " 'Red_cockaded_Woodpecker',\n",
       " 'Red_headed_Woodpecker',\n",
       " 'Downy_Woodpecker',\n",
       " 'Bewick_Wren',\n",
       " 'Cactus_Wren',\n",
       " 'Carolina_Wren',\n",
       " 'House_Wren',\n",
       " 'Marsh_Wren',\n",
       " 'Rock_Wren',\n",
       " 'Winter_Wren',\n",
       " 'Common_Yellowthroat']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45aebb2d-9e3e-4b43-a9e8-34e16355dd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 5994\n",
      "Validation set size: 5794\n"
     ]
    }
   ],
   "source": [
    "# Путь к данным\n",
    "data_dir = '/home/oldmovielover/Загрузки/CUB_200_2011/CUB_200_2011'\n",
    "images_dir = os.path.join(data_dir, 'images')\n",
    "train_test_split_file = os.path.join(data_dir, 'train_test_split.txt')\n",
    "\n",
    "# Определим трансформации для данных\n",
    "data_transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),  # Рандомное изменение размера\n",
    "    transforms.RandomRotation(15),      # Рандомный поворот на 15 градусов\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data_transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Считываем информацию о разделении на train и test\n",
    "def get_train_test_split():\n",
    "    with open(train_test_split_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Парсим строки, где 0 - test, 1 - train\n",
    "    train_indices = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    for line in lines:\n",
    "        image_id, is_train = line.strip().split()\n",
    "        image_id = int(image_id) - 1  # Нумерация с 1, поэтому уменьшим на 1\n",
    "        if is_train == '1':\n",
    "            train_indices.append(image_id)\n",
    "        else:\n",
    "            valid_indices.append(image_id)\n",
    "    \n",
    "    return train_indices, valid_indices\n",
    "\n",
    "# Кастомный датасет для загрузки данных\n",
    "class CUBDataset(Dataset):\n",
    "    def __init__(self, images_dir, split_indices, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.split_indices = split_indices\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Считываем метки классов\n",
    "        self.class_names = sorted(os.listdir(images_dir))  # Сортируем по имени папки\n",
    "\n",
    "        # Заполняем пути к изображениям и их метки\n",
    "        for class_idx, class_name in enumerate(self.class_names):\n",
    "            class_folder = os.path.join(self.images_dir, class_name)\n",
    "            \n",
    "            if os.path.exists(class_folder):\n",
    "                # Собираем изображения для каждой папки класса\n",
    "                for image_name in os.listdir(class_folder):\n",
    "                    image_path = os.path.join(class_folder, image_name)\n",
    "                    self.image_paths.append(image_path)\n",
    "                    self.labels.append(class_idx)\n",
    "            else:\n",
    "                print(f\"Папка для класса {class_name} не найдена: {class_folder}\")\n",
    "\n",
    "        # Используем только индексы из train или valid\n",
    "        self.image_paths = [self.image_paths[i] for i in self.split_indices]\n",
    "        self.labels = [self.labels[i] for i in self.split_indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Загружаем train и test индексы\n",
    "train_indices, valid_indices = get_train_test_split()\n",
    "\n",
    "# Создаем тренировочный и тестовый датасеты\n",
    "train_dataset = CUBDataset(images_dir, train_indices, transform=data_transform_train)\n",
    "valid_dataset = CUBDataset(images_dir, valid_indices, transform=data_transform_test)\n",
    "\n",
    "# Создаем DataLoader для тренировки и тестирования\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Проверка: выводим количество элементов в датасетах\n",
    "print(f\"Training set size: {len(train_loader.dataset)}\")\n",
    "print(f\"Validation set size: {len(valid_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f821670-fa4d-446a-9c52-a0380cc3bba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(valid_loader))[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39bdff41-8914-481a-9432-a476ea88c238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 Labels shape: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1])\n",
      "Batch 2 Labels shape: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 2, 2, 2, 2])\n",
      "Batch 3 Labels shape: tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3])\n",
      "Batch 1 Labels shape: tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4])\n",
      "Batch 2 Labels shape: tensor([4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6])\n",
      "Batch 3 Labels shape: tensor([6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        8, 8, 8, 8, 8, 8, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "train_iterator = iter(valid_loader)\n",
    "\n",
    "# Извлекаем три следующих батча\n",
    "batch_1 = next(train_iterator)\n",
    "batch_2 = next(train_iterator)\n",
    "batch_3 = next(train_iterator)\n",
    "batch_4 = next(train_iterator)\n",
    "batch_5 = next(train_iterator)\n",
    "batch_6 = next(train_iterator)\n",
    "\n",
    "# Каждый батч — это кортеж (image, label)\n",
    "# Можете получить данные и метки из этих батчей\n",
    "images_1, labels_1 = batch_1\n",
    "images_2, labels_2 = batch_2\n",
    "images_3, labels_3 = batch_3\n",
    "images_4, labels_4 = batch_4\n",
    "images_5, labels_5 = batch_5\n",
    "images_6, labels_6 = batch_6\n",
    "\n",
    "# Выводим размеры изображений и меток для проверки\n",
    "print(\"Batch 1 Labels shape:\", labels_1)\n",
    "print(\"Batch 2 Labels shape:\", labels_2)\n",
    "print(\"Batch 3 Labels shape:\", labels_3)\n",
    "print(\"Batch 1 Labels shape:\", labels_4)\n",
    "print(\"Batch 2 Labels shape:\", labels_5)\n",
    "print(\"Batch 3 Labels shape:\", labels_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23b021b1-4db8-4b0c-8036-1d7d3254bdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDenseNet(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "\n",
    "    self.model = models.densenet121(weights=DenseNet121_Weights.DEFAULT).to(DEVICE)\n",
    "    self.model.classifier = nn.Linear(in_features=1024, out_features=200)\n",
    "\n",
    "    for param in self.model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in self.model.features.denseblock4.denselayer16.parameters():\n",
    "        param.requires_grad = True\n",
    "      \n",
    "    self.model.classifier.weight.requires_grad = True\n",
    "    self.model.classifier.bias.requires_grad = True\n",
    "\n",
    "  def forward(self, x):\n",
    "      return self.model(x)\n",
    "\n",
    "model = MyDenseNet()\n",
    "model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "420bd85f-4d56-4752-8a06-3c37e5f32023",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbae2ba5-864d-4da5-91a7-3d8fda6d4a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c916b410-0e13-4771-8b30-e2e9733308b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0  loss_train: 4.480, loss_valid: 3.134\n",
      "\t  metrics_train: 0.126, metrics_valid: 0.299\n"
     ]
    }
   ],
   "source": [
    "train_epoch_acc = []\n",
    "train_epoch_losses = []\n",
    "valid_epoch_losses = []\n",
    "valid_epoch_acc = []\n",
    "\n",
    "# Перебор эпох\n",
    "for epoch in range(1):\n",
    "    # Обучение модели\n",
    "    model.train()\n",
    "    loss_batch = []\n",
    "    acc_batch = []\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        # Получение предсказаний\n",
    "        preds = model(images)  # без squeeze(-1), если выход имеет правильную форму\n",
    "\n",
    "        # Вычисление потерь\n",
    "        loss = criterion(preds, labels)\n",
    "        loss_batch.append(loss.item())\n",
    "\n",
    "        # Вычисление точности\n",
    "        accuracy = (preds.argmax(dim=1) == labels).cpu().numpy().mean()\n",
    "        acc_batch.append(accuracy)\n",
    "\n",
    "        # Обратное распространение и обновление весов\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Сохранение статистики\n",
    "    train_epoch_losses.append(np.mean(loss_batch))\n",
    "    train_epoch_acc.append(np.mean(acc_batch))\n",
    "\n",
    "    # Оценка модели\n",
    "    model.eval()\n",
    "    loss_batch = []\n",
    "    acc_batch = []\n",
    "    for images, labels in valid_loader:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        # Без обновления градиентов\n",
    "        with torch.no_grad():\n",
    "            preds = model(images)\n",
    "\n",
    "        # Вычисление потерь\n",
    "        loss = criterion(preds, labels)\n",
    "        loss_batch.append(loss.item())\n",
    "\n",
    "        # Вычисление точности\n",
    "        accuracy = (preds.argmax(dim=1) == labels).cpu().numpy().mean()\n",
    "        acc_batch.append(accuracy)\n",
    "\n",
    "    # Сохранение статистики для валидации\n",
    "    valid_epoch_losses.append(np.mean(loss_batch))\n",
    "    valid_epoch_acc.append(np.mean(acc_batch))\n",
    "\n",
    "    # Вывод статистики\n",
    "    print(f'Epoch: {epoch}  loss_train: {train_epoch_losses[-1]:.3f}, loss_valid: {valid_epoch_losses[-1]:.3f}')\n",
    "    print(f'\\t  metrics_train: {train_epoch_acc[-1]:.3f}, metrics_valid: {valid_epoch_acc[-1]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd80212-04f2-4b5c-9e4f-6153527a28f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in self.model.named_children():\n",
    "            if \"denselayer16\" in name:  # Можете использовать имя нужного слоя\n",
    "                for param in module.parameters():\n",
    "                    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88e0e574-5c4f-4808-83b6-dd4e010c3967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4916a61c-2a86-4e09-94d1-e289e9c1a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устройство (CPU или GPU)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Пути к данным\n",
    "DATA_DIR = \"/home/oldmovielover/Загрузки/CUB_200_2011/CUB_200_2011/images\"  # Путь к папке с изображениями\n",
    "IMAGES_FILE = \"/home/oldmovielover/Загрузки/CUB_200_2011/CUB_200_2011/images.txt\"\n",
    "LABELS_FILE = \"/home/oldmovielover/Загрузки/CUB_200_2011/CUB_200_2011/image_class_labels.txt\"\n",
    "SPLIT_FILE = \"/home/oldmovielover/Загрузки/CUB_200_2011/CUB_200_2011/train_test_split.txt\"\n",
    "\n",
    "# Гиперпараметры\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 200\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 25\n",
    "\n",
    "# Загрузка данных из файлов\n",
    "def load_data(images_file, labels_file, split_file, data_dir):\n",
    "    # Загрузка всех изображений и их меток\n",
    "    images_df = pd.read_csv(images_file, sep=' ', header=None, names=['id', 'file_path'])\n",
    "    labels_df = pd.read_csv(labels_file, sep=' ', header=None, names=['id', 'label'])\n",
    "    split_df = pd.read_csv(split_file, sep=' ', header=None, names=['id', 'is_train'])\n",
    "\n",
    "    # Объединение всех данных в один DataFrame\n",
    "    data = images_df.merge(labels_df, on='id').merge(split_df, on='id')\n",
    "    data['file_path'] = data['file_path'].apply(lambda x: os.path.join(data_dir, x))\n",
    "    \n",
    "    # Разделение на обучающую и тестовую выборки\n",
    "    train_data = data[data['is_train'] == 1]\n",
    "    val_data = data[data['is_train'] == 0]\n",
    "\n",
    "    return train_data['file_path'].values, train_data['label'].values - 1, \\\n",
    "           val_data['file_path'].values, val_data['label'].values - 1\n",
    "\n",
    "# Загрузка данных\n",
    "train_image_paths, train_labels, val_image_paths, val_labels = load_data(IMAGES_FILE, LABELS_FILE, SPLIT_FILE, DATA_DIR)\n",
    "\n",
    "# Класс для набора данных\n",
    "class CUBDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Трансформации данных\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Создание наборов данных и DataLoader\n",
    "train_dataset = CUBDataset(train_image_paths, train_labels, transform=train_transforms)\n",
    "val_dataset = CUBDataset(val_image_paths, val_labels, transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Модель DenseNet121\n",
    "class MyDenseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Загрузка предобученной модели\n",
    "        self.model = models.densenet121(weights=DenseNet121_Weights.DEFAULT).to(DEVICE)\n",
    "        self.model.classifier = nn.Linear(in_features=1024, out_features=200)\n",
    "    \n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "        for param in self.model.features.denseblock4.denselayer16.parameters():\n",
    "            param.requires_grad = True\n",
    "          \n",
    "        self.model.classifier.weight.requires_grad = True\n",
    "        self.model.classifier.bias.requires_grad = True\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Инициализация модели\n",
    "model = MyDenseNet().to(DEVICE)\n",
    "\n",
    "# Определение функции потерь и оптимизатора\n",
    "criterion = nn.CrossEntropyLoss()  # Если нужно использовать веса классов, добавьте weight=class_weights\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Функция для обучения модели\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, epochs):\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Обучение\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Оценка на валидационной выборке\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}, Validation Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456827fb-fe72-4b08-b40e-3a3115c68e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, criterion, optimizer, train_loader, val_loader, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6defaf-f840-4745-b4b2-49165a2749f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class MyResNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # Загружаем ResNet-50\n",
    "        self.model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        \n",
    "        # Заменяем последний слой (fc) для 200 классов (CUB-200-2011)\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(1024, 200),  # 200 классов для CUB-200-2011\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        # Замораживаем все параметры\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Размораживаем последние слои (например, layer4)\n",
    "        for param in self.model.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "model = MyResNet()\n",
    "model.to(DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
